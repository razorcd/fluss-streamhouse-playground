x-common-environment: &common-environment
  AWS_ACCESS_KEY_ID: admin
  AWS_SECRET_ACCESS_KEY: password
  AWS_REGION: us-east-1

services:
  
  # Fluss cluster
  
  fluss-coordinator-server:
    image: apache/fluss:0.8.0-incubating
    container_name: fluss-coordinator-server
    volumes:
      - ./lib:/tmp/lib
    ports:
      - "9123:9123"
    entrypoint:
      [
        "sh",
        "-c",
        "cp -v /tmp/lib/*.jar /opt/fluss/plugins/iceberg/ && exec /docker-entrypoint.sh coordinatorServer",
      ]
    depends_on:
      - zookeeper-fluss
      - rest
    networks:
      iceberg_net:
    environment:
      - |
        FLUSS_PROPERTIES=
        zookeeper.address: zookeeper-fluss:2181
        bind.listeners: FLUSS://fluss-coordinator-server:9123
        remote.data.dir: /tmp/fluss/remote-data
        datalake.format: iceberg
        datalake.iceberg.type: rest
        datalake.iceberg.warehouse: s3://warehouse/
        datalake.iceberg.uri: http://rest:8181
        datalake.iceberg.io-impl: org.apache.iceberg.aws.s3.S3FileIO
        datalake.iceberg.s3.endpoint: http://minio:9000
        datalake.iceberg.s3.path-style-access: true
  fluss-tablet-server:
    image: apache/fluss:0.8.0-incubating
    container_name: fluss-tablet-server
    command: tabletServer
    ports:
      - "9124:9123"
    depends_on:
      - fluss-coordinator-server
    networks:
      iceberg_net:
    environment:
      - |
        FLUSS_PROPERTIES=
        zookeeper.address: zookeeper-fluss:2181
        bind.listeners: FLUSS://fluss-tablet-server:9123
        data.dir: /tmp/fluss/data
        remote.data.dir: /tmp/fluss/remote-data
        kv.snapshot.interval: 0s
        datalake.format: iceberg
        datalake.iceberg.type: rest
        datalake.iceberg.warehouse: s3://warehouse/
        datalake.iceberg.uri: http://rest:8181
        datalake.iceberg.io-impl: org.apache.iceberg.aws.s3.S3FileIO
        datalake.iceberg.s3.endpoint: http://minio:9000
        datalake.iceberg.s3.path-style-access: true    

  
  # Flink Lake Tiering Service for Fluss to Iceberg
  
  flink-jobmanager:
    image: fluss/quickstart-flink-iceberg:1.20-0.8.0
    container_name: flink-jobmanager
    ports:
      - "8083:8081"
    command: jobmanager
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
  flink-taskmanager:
    image: fluss/quickstart-flink-iceberg:1.20-0.8.0
    container_name: flink-taskmanager
    depends_on:
      - flink-jobmanager
    command: taskmanager
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 10
        taskmanager.memory.process.size: 2048m
        taskmanager.memory.framework.off-heap.size: 256m
        
  flink-tiering:
    image: fluss/quickstart-flink-iceberg:1.20-0.8.0
    depends_on:
      - flink-jobmanager
      - fluss-coordinator-server
      - rest
      - minio
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      /opt/flink/bin/flink run -D rest.address=flink-jobmanager -D rest.port=8081 /opt/flink/opt/fluss-flink-tiering-0.8-SNAPSHOT.jar --fluss.bootstrap.servers fluss-coordinator-server:9123 --datalake.format iceberg --datalake.iceberg.type rest --datalake.iceberg.warehouse s3://warehouse/ --datalake.iceberg.uri http://rest:8181 --datalake.iceberg.io-impl org.apache.iceberg.aws.s3.S3FileIO --datalake.iceberg.s3.endpoint http://minio:9000 --datalake.iceberg.s3.path-style-access true
      "


  zookeeper-fluss:
    container_name: zookeeper-fluss
    restart: always
    image: zookeeper:3.9.2
    networks:
      iceberg_net:


  # Kafka

  zookeeper-kafka:
    image: 'confluentinc/cp-zookeeper:7.8.0'
    container_name: 'zookeeper-kafka'
    restart: 'unless-stopped'
    ports:
      - '2181:2181'
    environment:
      - 'ZOOKEEPER_CLIENT_PORT=2181'
    healthcheck:
      test: 'echo stat | nc localhost $$ZOOKEEPER_CLIENT_PORT'
    networks:
      iceberg_net:

  kafka-broker:
    image: 'confluentinc/cp-kafka:7.8.0'
    hostname: kafka
    container_name: kafka-broker
  #    restart: 'unless-stopped'
    depends_on:
      - 'zookeeper-kafka'
    ports:
      - 9092:9092
      - 29092:29092
    environment:
      - 'KAFKA_ZOOKEEPER_CONNECT=zookeeper-kafka:2181'
      - 'KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      - 'KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092,PLAINTEXT_HOST://kafka-broker:29092'
      - 'KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1'
    healthcheck:
      test: [ "CMD", "nc", "-z", "localhost", "9092" ]
    networks:
      iceberg_net:

  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    restart: unless-stopped
    depends_on:
      - kafka-broker
    ports:
      - 8082:8080
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka-server:
              properties:
                bootstrap.servers: "kafka-broker:29092"
    networks:
      iceberg_net:


  #Iceberg

  rest:
    image: apache/iceberg-rest-fixture
    container_name: iceberg-rest
    networks:
      iceberg_net:
    ports:
      - 8181:8181
    environment:
      <<: *common-environment
      CATALOG_WAREHOUSE: s3://warehouse/
      CATALOG_IO__IMPL: org.apache.iceberg.aws.s3.S3FileIO
      CATALOG_S3_ENDPOINT: http://minio:9000

  minio:
    image: minio/minio
    container_name: minio
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password
      MINIO_DOMAIN: minio
    networks:
      iceberg_net:
        aliases:
          - warehouse.minio
    volumes:
      - minio_data:/data
    ports:
      - 9001:9001
      - 9000:9000
    command: ["server", "/data", "--console-address", ":9001"]

  mc:
    depends_on:
      - minio
    image: minio/mc
    container_name: mc
    networks:
      iceberg_net:
    environment:
      - AWS_ACCESS_KEY_ID=admin
      - AWS_SECRET_ACCESS_KEY=password
      - AWS_REGION=us-east-1
    entrypoint: |
      /bin/sh -c "
      until (/usr/bin/mc alias set minio http://minio:9000 admin password) do echo '...waiting...' && sleep 1; done;
      /usr/bin/mc rm -r --force minio/warehouse;
      /usr/bin/mc mb minio/warehouse;
      /usr/bin/mc policy set public minio/warehouse;
      tail -f /dev/null
      "

networks:
  iceberg_net:

volumes:
  minio_data:
